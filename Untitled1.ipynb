{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, UpSampling2D, ReLU\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from math import sin, cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_matrix = np.array([[2304.5479, 0,  1686.2379],\n",
    "                          [0, 2305.8757, 1354.9849],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "camera_matrix_inv = np.linalg.inv(camera_matrix)\n",
    "IMG_SHAPE = (2710, 3384, 3)\n",
    "\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('sample_submission.csv')\n",
    "\n",
    "def imread(path, fast_mode=False):\n",
    "    img = cv2.imread(path)\n",
    "    if not fast_mode and img is not None and len(img.shape) == 3:\n",
    "        img = np.array(img[:, :, ::-1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = [\n",
    "        'baojun-310-2017','biaozhi-3008','biaozhi-liangxiang','bieke-yinglang-XT',\n",
    "        'biyadi-2x-F0','changanbenben','dongfeng-DS5','feiyate',\n",
    "        'fengtian-liangxiang','fengtian-MPV','jilixiongmao-2015','lingmu-aotuo-2009',\n",
    "        'lingmu-swift','lingmu-SX4-2012','sikeda-jingrui','fengtian-weichi-2006',\n",
    "        '037-CAR02','aodi-a6','baoma-330','baoma-530',\n",
    "        'baoshijie-paoche','bentian-fengfan','biaozhi-408','biaozhi-508',\n",
    "        'bieke-kaiyue','fute','haima-3','kaidilake-CTS',\n",
    "        'leikesasi','mazida-6-2015','MG-GT-2015','oubao',\n",
    "        'qiya','rongwei-750','supai-2016','xiandai-suonata',\n",
    "        'yiqi-benteng-b50','bieke','biyadi-F3','biyadi-qin',\n",
    "        'dazhong','dazhongmaiteng','dihao-EV','dongfeng-xuetielong-C6',\n",
    "        'dongnan-V3-lingyue-2011','dongfeng-yulong-naruijie','019-SUV','036-CAR01',\n",
    "        'aodi-Q7-SUV','baojun-510','baoma-X5','baoshijie-kayan',\n",
    "        'beiqi-huansu-H3','benchi-GLK-300','benchi-ML500','fengtian-puladuo-06',\n",
    "        'fengtian-SUV-gai','guangqi-chuanqi-GS4-2015','jianghuai-ruifeng-S3','jili-boyue',\n",
    "        'jipu-3','linken-SUV','lufeng-X8','qirui-ruihu',\n",
    "        'rongwei-RX5','sanling-oulande','sikeda-SUV','Skoda_Fabia-2011',\n",
    "        'xiandai-i25-2016','yingfeinidi-qx80','yingfeinidi-SUV','benchi-SUR',\n",
    "        'biyadi-tang','changan-CS35-2012','changan-cs5','changcheng-H6-2016',\n",
    "        'dazhong-SUV','dongfeng-fengguang-S560','dongfeng-fengxing-SX6'\n",
    "        ]\n",
    "carid2name={}\n",
    "for i in range(len(cars)):\n",
    "    carid2name[i]=cars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2cords(s):\n",
    "    names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']\n",
    "    cords=[]\n",
    "    for i in np.array(s.split()).reshape([-1,7]):\n",
    "        cords.append(dict(zip(names, i.astype(float))))\n",
    "        if 'id' in cords[-1]:\n",
    "            cords[-1]['id']=int(cords[-1]['id'])\n",
    "            \n",
    "    return cords\n",
    "\n",
    "def rotate(x, angle):\n",
    "    x = x + angle\n",
    "    x = x - (x + np.pi) // (2 * np.pi) * 2 * np.pi\n",
    "    return x\n",
    "\n",
    "def get_img_coords(s):\n",
    "    coords = str2coords(s)\n",
    "    xs = [c['x'] for c in coords]\n",
    "    ys = [c['y'] for c in coords]\n",
    "    zs = [c['z'] for c in coords]\n",
    "    P = np.array(list(zip(xs, ys, zs))).T\n",
    "    img_p = np.dot(camera_matrix, P).T\n",
    "    img_p[:, 0] /= img_p[:, 2]\n",
    "    img_p[:, 1] /= img_p[:, 2]\n",
    "    img_xs = img_p[:, 0]\n",
    "    img_ys = img_p[:, 1]\n",
    "    img_zs = img_p[:, 2]\n",
    "    return img_xs, img_ys\n",
    "\n",
    "def euler_to_Rot(yaw, pitch, roll):\n",
    "    Y = np.array([[cos(yaw), 0, sin(yaw)],\n",
    "                  [0, 1, 0],\n",
    "                  [-sin(yaw), 0, cos(yaw)]])\n",
    "    P = np.array([[1, 0, 0],\n",
    "                  [0, cos(pitch), -sin(pitch)],\n",
    "                  [0, sin(pitch), cos(pitch)]])\n",
    "    R = np.array([[cos(roll), -sin(roll), 0],\n",
    "                  [sin(roll), cos(roll), 0],\n",
    "                  [0, 0, 1]])\n",
    "    return np.dot(Y, np.dot(P, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='car_models_json/'\n",
    "\n",
    "def draw_obj(image, vertices, triangles, num_for_color):\n",
    "    for t in triangles:\n",
    "        coord = np.array([vertices[t[0]][:2], vertices[t[1]][:2], vertices[t[2]][:2]], dtype=np.int32)\n",
    "#         cv2.fillConvexPoly(image, coord, (0,0,255))\n",
    "        place = num_for_color%3\n",
    "        color = [0,0,0]\n",
    "        color[place] = 255\n",
    "        color = tuple(color)\n",
    "        cv2.polylines(image, np.int32([coord]), 1, color)\n",
    "    return image\n",
    "\n",
    "def draw_bw(image, vertices, triangles, num_for_color):\n",
    "    for t in triangles:\n",
    "        coord = np.array([vertices[t[0]][:2], vertices[t[1]][:2], vertices[t[2]][:2]], dtype=np.int32)\n",
    "        color = [255,255,255]\n",
    "        color = tuple(color)\n",
    "        cv2.polylines(image, np.int32([coord]), 1, color)\n",
    "    return image\n",
    "\n",
    "def visualize(img, coords):\n",
    "    img = img.copy()\n",
    "    num_for_color = 0\n",
    "    masks = np.zeros(8*img.shape[0]*img.shape[1]).reshape(8, img.shape[0], img.shape[1])\n",
    "    for point in coords:\n",
    "        c_model = carid2name[int(point['id'])] + '.json'\n",
    "        with open(PATH+c_model) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        vertices = np.array(data['vertices'])\n",
    "        vertices[:, 1] = -vertices[:, 1]\n",
    "        triangles = np.array(data['faces']) - 1\n",
    "        x, y, z = point['x'], point['y'], point['z']\n",
    "        yaw, pitch, roll = -point['pitch'], -point['yaw'], -point['roll']\n",
    "        Rt = np.eye(4)\n",
    "        t = np.array([x, y, z])\n",
    "        Rt[:3, 3] = t\n",
    "        Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n",
    "        Rt = Rt[:3, :]\n",
    "        P = np.ones((vertices.shape[0],vertices.shape[1]+1))\n",
    "        P[:, :-1] = vertices\n",
    "        P = P.T\n",
    "        img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n",
    "        img_cor_points = img_cor_points.T\n",
    "        img_cor_points[:, 0] /= img_cor_points[:, 2]\n",
    "        img_cor_points[:, 1] /= img_cor_points[:, 2]\n",
    "        img_cor_points = img_cor_points.astype(int)\n",
    "        # find counters\n",
    "        overlay = np.zeros_like(img)\n",
    "        overlay = draw_bw(overlay, img_cor_points, triangles, num_for_color)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "        _, contours, hierarchy = cv2.findContours(overlay, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # draw counters\n",
    "        for i in range(len(contours)):\n",
    "            if hierarchy[0][i][3]==-1:\n",
    "                overlay = cv2.drawContours(overlay, contours, i, 255, -1)\n",
    "        # for instance segmentation\n",
    "        overlay_contours = overlay\n",
    "        overlay_contours = cv2.Canny(overlay_contours, 30, 200)\n",
    "        kernel = np.ones((8,8),np.uint8)\n",
    "        overlay_contours = cv2.dilate(overlay_contours,kernel,iterations = 1)\n",
    "        # logits\n",
    "        masks[0][overlay!=0] = 1\n",
    "        # for IS\n",
    "        masks[0][overlay_contours!=0] = 0\n",
    "        # x\n",
    "        masks[1][overlay!=0] = point['x']/100\n",
    "        # y\n",
    "        masks[2][overlay!=0] = point['y']/100\n",
    "        # z\n",
    "        masks[3][overlay!=0] = point['z']/100\n",
    "        # yaw\n",
    "        masks[4][overlay!=0] = point['yaw']\n",
    "        # pitch sin\n",
    "        psin = sin(point['pitch'])\n",
    "        masks[5][overlay!=0] = psin\n",
    "        # pitch cos\n",
    "        pcos = cos(point['pitch'])\n",
    "        masks[6][overlay!=0] = pcos\n",
    "        # roll\n",
    "        masks[7][overlay!=0] = rotate(point['roll'],np.pi)\n",
    "        \n",
    "        #plt.imshow(overlay)\n",
    "        #plt.show()\n",
    "        img = draw_obj(img, img_cor_points, triangles, num_for_color)\n",
    "        num_for_color += 1\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample\n",
    "img=cv2.imread('train_images/ID_0be7ae789.jpg')\n",
    "cord=np.array(train.loc[train['ImageId']=='ID_0be7ae789', 'PredictionString'])\n",
    "point=str2cords(cord[0])[3]\n",
    "cmodel=carid2name[int(point['id'])]\n",
    "with open('car_models_json/'+cmodel+'.json') as file:\n",
    "    data=json.load(file)\n",
    "vertices=np.array(data['vertices'])\n",
    "vertices[:, 1]=-vertices[:, 1]\n",
    "traingles=np.array(data['faces'])-1\n",
    "x,y,z=point['x'], point['y'], point['z']\n",
    "yaw, pitch, roll=-point['yaw'], -point['pitch'], -point['roll']\n",
    "Rt = np.eye(4)\n",
    "t = np.array([x, y, z])\n",
    "Rt[:3, 3] = t\n",
    "Rt[:3, :3] = euler_to_Rot(yaw, pitch, roll).T\n",
    "Rt = Rt[:3, :]\n",
    "P = np.ones((vertices.shape[0],vertices.shape[1]+1))\n",
    "P[:, :-1] = vertices\n",
    "P = P.T\n",
    "img_cor_points = np.dot(camera_matrix, np.dot(Rt, P))\n",
    "img_cor_points = img_cor_points.T\n",
    "img_cor_points[:, 0] /= img_cor_points[:, 2]\n",
    "img_cor_points[:, 1] /= img_cor_points[:, 2]\n",
    "img_cor_points = img_cor_points.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay=np.zeros_like(img)\n",
    "for t in traingles:\n",
    "    cor=np.array([img_cor_points[t[0]][:2], img_cor_points[t[1]][:2], img_cor_points[t[2]][:2]])\n",
    "    color=tuple([255,255,255])\n",
    "    cv2.polylines(overlay, np.int32([cor]), 1, color)\n",
    "    \n",
    "overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "_, contours, hierarchy = cv2.findContours(overlay, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # draw counters\n",
    "for i in range(len(contours)):\n",
    "    if hierarchy[0][i][3]==-1:\n",
    "        overlay = cv2.drawContours(overlay, contours, i, 255, -1)\n",
    "        \n",
    "overlay_contours = cv2.Canny(overlay, 30, 200)\n",
    "kernel = np.ones((8,8),np.uint8)\n",
    "overlay_contours = cv2.dilate(overlay_contours,kernel,iterations = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 8698336, 0.0409935: 472304}\n"
     ]
    }
   ],
   "source": [
    "uniq, c=np.unique(mask[0], return_counts=True)\n",
    "print(dict(zip(uniq, c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.zeros(8*img.shape[0]*img.shape[1]).reshape(8, img.shape[0], img.shape[1])\n",
    "mask[0][overlay!=0]=point['x']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class conv_block(tf.keras.Model):\n",
    "    def __init__(self, ch):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv=Sequential([Conv2D(ch, 3,strides=(np.int64(1),np.int64(1)), padding='same', data_format='channels_first'),\n",
    "                                BatchNormalization(),\n",
    "                              ReLU(),\n",
    "                         Conv2D(ch, 3, strides=(np.int64(1),np.int64(1)), padding='same', data_format='channels_first'),\n",
    "                              BatchNormalization(),\n",
    "                              ReLU()])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x=self.conv(x)\n",
    "        return x\n",
    "\n",
    "class network(tf.keras.Model):\n",
    "    def __init__(self, n_classes):\n",
    "        super(network, self).__init__()\n",
    "        self.c0=conv_block(32)\n",
    "        self.m0=MaxPool2D(2)\n",
    "        self.c1=conv_block(64)\n",
    "        self.m1=MaxPool2D(2)\n",
    "        self.c2=conv_block(128)\n",
    "        self.m2=MaxPool2D(2)\n",
    "        self.c3=conv_block(256)\n",
    "        self.m3=MaxPool2D(2)\n",
    "        self.c4=conv_block(256)\n",
    "        self.up0=UpSampling2D(size=(2,2), interpolation='bilinear')\n",
    "        self.c5=conv_block(128)\n",
    "        self.up1=UpSampling2D(size=(2,2), interpolation='bilinear')\n",
    "        self.c6=conv_block(64)\n",
    "        self.up2=UpSampling2D(size=(2,2), interpolation='bilinear')\n",
    "        self.c7=conv_block(32)\n",
    "        self.up3=UpSampling2D(size=(2,2), interpolation='bilinear')\n",
    "        self.last=conv_block(n_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        x0=self.c0(x)\n",
    "        #print(x0)\n",
    "        x1=self.c1(self.m0(x0))\n",
    "        #print(x1)\n",
    "        x2=self.c2(self.m1(x1))\n",
    "        #print(x2)\n",
    "        x3=self.c3(self.m2(x2))\n",
    "        #print(x3)\n",
    "        x=self.c4(self.m3(x3))\n",
    "        #print(x)\n",
    "        x=tf.concat([x3, self.up0(x)], 1)\n",
    "        #print(x)\n",
    "        x=self.up1(self.c5(x))\n",
    "        #print(x)\n",
    "        x=tf.concat([x2, x], 1)\n",
    "        #print(x)\n",
    "        x=self.up2(self.c6(x))\n",
    "        #print(x)\n",
    "        x=tf.concat([x1, x], 1)\n",
    "        #print(x)\n",
    "        x=self.up3(self.c7(x))\n",
    "        #print(x)\n",
    "        x=tf.concat([x0, x], 1)\n",
    "        #print(x)\n",
    "        x=self.last(x)\n",
    "        #print(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val=train_test_split(train, test_size=0.9, random_state=42)\n",
    "test=test\n",
    "\n",
    "scale=2\n",
    "BATCH_SIZE=5\n",
    "EPOCH=10\n",
    "\n",
    "def sample_fetcher(dframe):\n",
    "    \n",
    "    for val in dframe.values:\n",
    "        Id=val[0]\n",
    "        ps=val[1]\n",
    "        img=imread('train_images/'+Id+'.jpg')\n",
    "        regr=visualize(img, str2cords(ps))\n",
    "        img=img[1430:, :, :]/255\n",
    "        img=cv2.resize(img, (640//scale, 480//scale))\n",
    "        img=np.rollaxis(img, 2, 0)\n",
    "        regr=regr[:, 1430:, :]\n",
    "        regr=np.rollaxis(np.rollaxis(regr, 2,0), 2, 0)\n",
    "        regr=cv2.resize(regr, (640//scale, 480//scale))\n",
    "        regr=np.rollaxis(regr, 2, 0)\n",
    "        mask=imread('train_masks/'+Id+'.jpg')\n",
    "        if type(mask)==np.ndarray:\n",
    "            mask=mask[1430:, :, :]\n",
    "            mask=cv2.resize(mask, (640//scale, 480//scale))\n",
    "            mask=np.rollaxis(mask, 2, 0)\n",
    "\n",
    "        if type(mask)!=np.ndarray:\n",
    "            mask=np.zeros(2710*3384*3).reshape(2710,3384,3)\n",
    "            mask=mask[1430: :, :]\n",
    "            mask=cv2.resize(mask, (640//scale, 480//scale))\n",
    "            mask=np.rollaxis(mask, 2, 0)\n",
    "\n",
    "            \n",
    "        img=tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "        regr=tf.convert_to_tensor(regr, dtype=tf.float32)\n",
    "        mask=tf.convert_to_tensor(mask, dtype=tf.float32)\n",
    "        \n",
    "        yield (img, regr, mask)\n",
    "        \n",
    "def train_sampler():\n",
    "    return sample_fetcher(train)\n",
    "        \n",
    "def valid_sampler():\n",
    "    return sample_fetcher(val)\n",
    "\n",
    "\n",
    "train_dataset=tf.data.Dataset.from_generator(generator=train_sampler, \n",
    "                                             output_types=(tf.float32, tf.float32, tf.float32))\n",
    "train_dataset=train_dataset.repeat()\n",
    "train_dataset=train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset=train_dataset.shuffle(10)\n",
    "\n",
    "valid_dataset=tf.data.Dataset.from_generator(generator=valid_sampler, output_types=(tf.float32, tf.float32, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred, regr, mask):\n",
    "    \n",
    "    pred_mask=tf.sigmoid(pred[:, 0])\n",
    "    pred_regr=pred[:, 1:]\n",
    "    with tf.compat.v1.variable_scope('loss'):\n",
    "        mask_loss=mask*tf.math.log(pred_mask+1e-12)+(1-mask)*tf.math.log(1-pred_mask+1e-12)\n",
    "        mask_loss=-tf.reduce_sum(tf.reduce_mean(mask_loss, 0))\n",
    "    \n",
    "        regr_loss=tf.reduce_sum( tf.reduce_sum( (tf.reduce_sum(tf.math.abs(pred_regr-regr), 1)*mask), 1))/tf.reduce_sum((tf.reduce_sum( mask, 1)), 1) \n",
    "        regr_loss=tf.reduce_mean(regr_loss, 0)\n",
    "    \n",
    "        total_loss=mask_loss+regr_loss\n",
    "        \n",
    "    #print(\"mask loss : \", mask_loss)\n",
    "    #print(\"regr loss : \", regr_loss)\n",
    "    #if not size_avg:\n",
    "     #   total_loss*=pred[0]\n",
    "                            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg=img[np.newaxis, :, :, :]\\nreg=regr[np.newaxis, :, :, :]\\nmask=mask[np.newaxis, :, :, :]\\n\\nout=model(img_)\\npred_mask=out[:, 0]\\npred_regr=out[:, 1:]\\n\\npred_regr=out[:, 1:]\\n\\nprint(pred_mask.shape)\\nprint(mask.shape)\\n\\n\\na=reg[:, 0]*tf.math.log(pred_mask + 1e-12)\\nprint(a)\\na_=tf.reduce_mean(a, 0)\\nprint(a_)\\na__=tf.reduce_sum(a_)\\nprint(a__)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(img, regr, mask)=next(train_sampler())\n",
    "'''\n",
    "img=img[np.newaxis, :, :, :]\n",
    "reg=regr[np.newaxis, :, :, :]\n",
    "mask=mask[np.newaxis, :, :, :]\n",
    "\n",
    "out=model(img_)\n",
    "pred_mask=out[:, 0]\n",
    "pred_regr=out[:, 1:]\n",
    "\n",
    "pred_regr=out[:, 1:]\n",
    "\n",
    "print(pred_mask.shape)\n",
    "print(mask.shape)\n",
    "\n",
    "\n",
    "a=reg[:, 0]*tf.math.log(pred_mask + 1e-12)\n",
    "print(a)\n",
    "a_=tf.reduce_mean(a, 0)\n",
    "print(a_)\n",
    "a__=tf.reduce_sum(a_)\n",
    "print(a__)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 240, 320])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq, count=np.unique(regr[1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "an=dict(zip(uniq, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.145415: 281,\n",
       " -0.14516151: 1,\n",
       " -0.14465195: 1,\n",
       " -0.14240281: 1,\n",
       " -0.1422022: 1,\n",
       " -0.1402652: 1,\n",
       " -0.1395915: 1,\n",
       " -0.135776: 6,\n",
       " -0.1355302: 1,\n",
       " -0.13299559: 1,\n",
       " -0.1293498: 1,\n",
       " -0.12930965: 1,\n",
       " -0.12770323: 1,\n",
       " -0.1269804: 1,\n",
       " -0.126137: 1032,\n",
       " -0.125138: 1,\n",
       " -0.12467434: 1,\n",
       " -0.123787895: 1,\n",
       " -0.12325605: 1,\n",
       " -0.121180646: 2,\n",
       " -0.119666256: 1,\n",
       " -0.11769838: 1,\n",
       " -0.11510009: 1,\n",
       " -0.111619584: 2,\n",
       " -0.11035296: 1,\n",
       " -0.10580829: 1,\n",
       " -0.10545234: 1,\n",
       " -0.104861: 902,\n",
       " -0.1040119: 1,\n",
       " -0.10355242: 2,\n",
       " -0.102363: 116,\n",
       " -0.102325834: 1,\n",
       " -0.10214388: 2,\n",
       " -0.10137729: 1,\n",
       " -0.10105145: 1,\n",
       " -0.100313544: 1,\n",
       " -0.0995245: 37,\n",
       " -0.099158846: 1,\n",
       " -0.09848247: 1,\n",
       " -0.09845787: 1,\n",
       " -0.09823711: 1,\n",
       " -0.09719844: 1,\n",
       " -0.0970105: 666,\n",
       " -0.096912906: 1,\n",
       " -0.096893385: 5,\n",
       " -0.09672553: 1,\n",
       " -0.0963859: 540,\n",
       " -0.095182285: 1,\n",
       " -0.094640814: 1,\n",
       " -0.0944932: 99,\n",
       " -0.09416366: 1,\n",
       " -0.0929411: 1,\n",
       " -0.092169076: 1,\n",
       " -0.09085717: 1,\n",
       " -0.090088494: 1,\n",
       " -0.08961298: 1,\n",
       " -0.0885603: 406,\n",
       " -0.08807529: 1,\n",
       " -0.0878228: 81,\n",
       " -0.08738203: 3,\n",
       " -0.08697022: 1,\n",
       " -0.08679971: 2,\n",
       " -0.08674012: 1,\n",
       " -0.08669411: 1,\n",
       " -0.0865236: 65,\n",
       " -0.0854234: 2,\n",
       " -0.085303545: 2,\n",
       " -0.0829381: 2,\n",
       " -0.08084307: 2,\n",
       " -0.08032256: 8,\n",
       " -0.07973813: 1,\n",
       " -0.079150766: 1,\n",
       " -0.07755129: 1,\n",
       " -0.07578945: 1,\n",
       " -0.07379845: 1,\n",
       " -0.0727075: 5,\n",
       " -0.071458176: 1,\n",
       " -0.06974123: 2,\n",
       " -0.06972399: 1,\n",
       " -0.06717737: 1,\n",
       " -0.0671013: 66,\n",
       " -0.066960596: 1,\n",
       " -0.06594419: 1,\n",
       " -0.0630685: 1,\n",
       " -0.061608396: 1,\n",
       " -0.060331713: 1,\n",
       " -0.059963625: 1,\n",
       " -0.055918433: 1,\n",
       " -0.052750643: 1,\n",
       " -0.05120501: 1,\n",
       " -0.0511815: 1,\n",
       " -0.050110415: 1,\n",
       " -0.04976225: 2,\n",
       " -0.048423152: 1,\n",
       " -0.04819295: 2,\n",
       " -0.047811314: 1,\n",
       " -0.04646376: 1,\n",
       " -0.0439776: 25,\n",
       " -0.041492: 33,\n",
       " -0.0373203: 1,\n",
       " -0.035165124: 1,\n",
       " -0.03457709: 3,\n",
       " -0.034211546: 1,\n",
       " -0.03308808: 1,\n",
       " -0.029426863: 4,\n",
       " -0.028780773: 1,\n",
       " -0.025302475: 1,\n",
       " -0.024377562: 1,\n",
       " -0.024234354: 2,\n",
       " -0.022890475: 1,\n",
       " -0.02102155: 1,\n",
       " -0.020494184: 3,\n",
       " -0.019006066: 1,\n",
       " -0.017478967: 4,\n",
       " -0.017070506: 1,\n",
       " -0.017059458: 1,\n",
       " -0.016605057: 1,\n",
       " -0.016586404: 1,\n",
       " -0.01616743: 2,\n",
       " -0.016063336: 1,\n",
       " -0.016051563: 1,\n",
       " -0.015747905: 3,\n",
       " -0.014761852: 4,\n",
       " -0.014759149: 1,\n",
       " -0.01463624: 2,\n",
       " -0.014199484: 1,\n",
       " -0.013926745: 1,\n",
       " -0.011182867: 1,\n",
       " -0.011159418: 1,\n",
       " -0.010247092: 1,\n",
       " -0.00956625: 16,\n",
       " -0.006741437: 1,\n",
       " -0.005617933: 1,\n",
       " -0.004904178: 1,\n",
       " -0.003939263: 1,\n",
       " -0.0032148014: 1,\n",
       " -0.0014138542: 1,\n",
       " -0.0012060003: 1,\n",
       " 0.0: 65728,\n",
       " 0.00039306554: 1,\n",
       " 0.0005267841: 1,\n",
       " 0.0006032163: 1,\n",
       " 0.0012924992: 1,\n",
       " 0.0013134056: 1,\n",
       " 0.0014793322: 1,\n",
       " 0.001732045: 1,\n",
       " 0.0017575049: 1,\n",
       " 0.0021282728: 2,\n",
       " 0.0023802407: 2,\n",
       " 0.0025624058: 1,\n",
       " 0.002864744: 1,\n",
       " 0.0028867768: 2,\n",
       " 0.0030526447: 1,\n",
       " 0.0031608976: 1,\n",
       " 0.0032114265: 2,\n",
       " 0.003413561: 1,\n",
       " 0.00346409: 174,\n",
       " 0.0036327415: 1,\n",
       " 0.005134764: 1,\n",
       " 0.006152335: 1,\n",
       " 0.007138276: 1,\n",
       " 0.0076098666: 1,\n",
       " 0.007705813: 1,\n",
       " 0.008517354: 1,\n",
       " 0.009555434: 3,\n",
       " 0.009557183: 2,\n",
       " 0.009651461: 2,\n",
       " 0.010020006: 14,\n",
       " 0.010488576: 2,\n",
       " 0.010639805: 1,\n",
       " 0.01081704: 1,\n",
       " 0.011464306: 1,\n",
       " 0.012524549: 1,\n",
       " 0.013367605: 1,\n",
       " 0.016389601: 1,\n",
       " 0.018097594: 2,\n",
       " 0.021857988: 1,\n",
       " 0.022315925: 1,\n",
       " 0.0229165: 1,\n",
       " 0.02367231: 1,\n",
       " 0.024548313: 2,\n",
       " 0.024727592: 1,\n",
       " 0.027276: 2,\n",
       " 0.02745491: 1,\n",
       " 0.02866805: 1,\n",
       " 0.03005635: 21,\n",
       " 0.031450026: 1,\n",
       " 0.031931646: 1,\n",
       " 0.0324531: 1,\n",
       " 0.03265481: 1,\n",
       " 0.0327308: 23,\n",
       " 0.03556439: 1,\n",
       " 0.035690065: 1,\n",
       " 0.036440387: 1,\n",
       " 0.03694972: 1,\n",
       " 0.03853189: 1,\n",
       " 0.04132748: 1,\n",
       " 0.041947737: 1,\n",
       " 0.04445482: 1,\n",
       " 0.044754833: 1,\n",
       " 0.0462377: 45,\n",
       " 0.04734462: 2,\n",
       " 0.047780667: 3,\n",
       " 0.04789964: 1,\n",
       " 0.048380744: 1,\n",
       " 0.049472895: 1,\n",
       " 0.0498609: 1,\n",
       " 0.050092693: 14,\n",
       " 0.050768834: 1,\n",
       " 0.05139434: 1,\n",
       " 0.051761948: 1,\n",
       " 0.05219912: 1,\n",
       " 0.05227644: 1,\n",
       " 0.05232479: 1,\n",
       " 0.052736286: 1,\n",
       " 0.0534841: 55,\n",
       " 0.054109544: 1,\n",
       " 0.054477133: 1,\n",
       " 0.055734932: 1,\n",
       " 0.056230437: 1,\n",
       " 0.056729894: 1,\n",
       " 0.0572059: 1,\n",
       " 0.0573361: 1714,\n",
       " 0.057485703: 1,\n",
       " 0.0579123: 263,\n",
       " 0.057984427: 1,\n",
       " 0.058234178: 1,\n",
       " 0.05846436: 1,\n",
       " 0.05848347: 1,\n",
       " 0.058967054: 1,\n",
       " 0.05898444: 1,\n",
       " 0.05948645: 1,\n",
       " 0.059488986: 1,\n",
       " 0.059852287: 1,\n",
       " 0.05998794: 1,\n",
       " 0.0601127: 3810,\n",
       " 0.062098183: 1,\n",
       " 0.06263181: 1,\n",
       " 0.0629353: 146,\n",
       " 0.06392075: 1,\n",
       " 0.064573705: 1,\n",
       " 0.0649062: 147}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nmodel.compile(optimizers=optm, loss=custom_loss, metrics=[custom_loss])\\nhistory=model.fit(train_dataset, steps_per_epoch=np.ceil(len(train)/BATCH_SIZE), \\n                 epochs=EPOCH, validation_data=valid_dataset, \\n                  validation_steps=int(np.ceil(len(val)/BATCH_SIZE)), use_multiprocessing=False)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=network(8)\n",
    "optm=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "''' \n",
    "model.compile(optimizers=optm, loss=custom_loss, metrics=[custom_loss])\n",
    "history=model.fit(train_dataset, steps_per_epoch=np.ceil(len(train)/BATCH_SIZE), \n",
    "                 epochs=EPOCH, validation_data=valid_dataset, \n",
    "                  validation_steps=int(np.ceil(len(val)/BATCH_SIZE)), use_multiprocessing=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 53273.207\n",
      "Epoch 000: Loss: 53244.383\n",
      "Epoch 000: Loss: 53245.020\n",
      "Epoch 000: Loss: 53244.719\n",
      "Epoch 000: Loss: 53243.984\n",
      "Epoch 000: Loss: 53246.266\n",
      "Epoch 000: Loss: 53246.547\n",
      "Epoch 000: Loss: 53246.738\n",
      "Epoch 000: Loss: 53245.957\n",
      "Epoch 000: Loss: 53249.766\n",
      "Epoch 000: Loss: 53244.785\n",
      "Epoch 000: Loss: 53352.910\n",
      "Epoch 000: Loss: 53327.578\n",
      "Epoch 000: Loss: 53263.000\n",
      "Epoch 000: Loss: 53245.984\n",
      "Epoch 000: Loss: 53266.414\n",
      "Epoch 000: Loss: 53275.219\n",
      "Epoch 000: Loss: 53280.758\n",
      "Epoch 000: Loss: 53247.316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-adb993bb1e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m#img=img[np.newaxis, :, :, :]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#regr=regr[np.newaxis, :, :, :]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(EPOCH):\n",
    "    \n",
    "    for img, regr, mask in train_dataset:\n",
    "        #img=img[np.newaxis, :, :, :]\n",
    "        #regr=regr[np.newaxis, :, :, :]\n",
    "        #mask=mask[np.newaxis, :, :, :]\n",
    "\n",
    "        #with tf.compat.v1.variable_scope('loss', reuse=True):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out=model(img)\n",
    "            loss=custom_loss(out, regr[:, 1:], regr[:, 0])\n",
    "\n",
    "            grads=tape.gradient(loss, model.trainable_variables)\n",
    "            \n",
    "            optm.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}\".format(_, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
